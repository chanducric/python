{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Titanic dataset\n",
    "train_data = pd.read_csv('train.csv')  # Make sure 'train.csv' is in the correct path\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing 'Age' values with the median\n",
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\n",
    "\n",
    "# Fill missing 'Embarked' values with the mode (most frequent)\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])\n",
    "\n",
    "# Drop the 'Cabin' column (too many missing values)\n",
    "train_data.drop('Cabin', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode 'Sex' column: male -> 0, female -> 1\n",
    "train_data['Sex'] = train_data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Encode 'Embarked' column: C -> 0, Q -> 1, S -> 2\n",
    "train_data['Embarked'] = train_data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale 'Age' and 'Fare' columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_data[['Age', 'Fare']] = scaler.fit_transform(train_data[['Age', 'Fare']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = train_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "y = train_data['Survived']\n",
    "\n",
    "# Split the data into training (70%), validation (15%), and test (15%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for Titanic data\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)  # Features\n",
    "        self.y = torch.tensor(y.values, dtype=torch.long)    # Target (Survived)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_dataset = TitanicDataset(X_train, y_train)\n",
    "val_dataset = TitanicDataset(X_val, y_val)\n",
    "test_dataset = TitanicDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Architecture\n",
    "class TitanicNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TitanicNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(7, 64)  # 7 input features\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)  # Output layer: 2 classes (Survived, Not Survived)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # ReLU activation\n",
    "        x = F.relu(self.fc2(x))  # ReLU activation\n",
    "        x = self.fc3(x)          # Output layer\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = TitanicNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # For binary classification (0 or 1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.3700, Train Accuracy: 83.79%, Val Accuracy: 84.33%\n",
      "Epoch 2/30, Loss: 0.3733, Train Accuracy: 84.11%, Val Accuracy: 84.33%\n",
      "Epoch 3/30, Loss: 0.3752, Train Accuracy: 84.11%, Val Accuracy: 78.36%\n",
      "Epoch 4/30, Loss: 0.3826, Train Accuracy: 83.79%, Val Accuracy: 85.07%\n",
      "Epoch 5/30, Loss: 0.3670, Train Accuracy: 85.23%, Val Accuracy: 83.58%\n",
      "Epoch 6/30, Loss: 0.3745, Train Accuracy: 84.91%, Val Accuracy: 85.07%\n",
      "Epoch 7/30, Loss: 0.3727, Train Accuracy: 85.07%, Val Accuracy: 83.58%\n",
      "Epoch 8/30, Loss: 0.3651, Train Accuracy: 85.23%, Val Accuracy: 83.58%\n",
      "Epoch 9/30, Loss: 0.3654, Train Accuracy: 85.23%, Val Accuracy: 82.84%\n",
      "Epoch 10/30, Loss: 0.3685, Train Accuracy: 84.75%, Val Accuracy: 84.33%\n",
      "Epoch 11/30, Loss: 0.3619, Train Accuracy: 84.59%, Val Accuracy: 80.60%\n",
      "Epoch 12/30, Loss: 0.3622, Train Accuracy: 84.27%, Val Accuracy: 83.58%\n",
      "Epoch 13/30, Loss: 0.3638, Train Accuracy: 85.23%, Val Accuracy: 82.84%\n",
      "Epoch 14/30, Loss: 0.3644, Train Accuracy: 84.43%, Val Accuracy: 83.58%\n",
      "Epoch 15/30, Loss: 0.3622, Train Accuracy: 85.39%, Val Accuracy: 83.58%\n",
      "Epoch 16/30, Loss: 0.3588, Train Accuracy: 84.43%, Val Accuracy: 82.09%\n",
      "Epoch 17/30, Loss: 0.3524, Train Accuracy: 85.39%, Val Accuracy: 83.58%\n",
      "Epoch 18/30, Loss: 0.3504, Train Accuracy: 85.07%, Val Accuracy: 82.84%\n",
      "Epoch 19/30, Loss: 0.3618, Train Accuracy: 86.04%, Val Accuracy: 84.33%\n",
      "Epoch 20/30, Loss: 0.3582, Train Accuracy: 84.91%, Val Accuracy: 82.84%\n",
      "Epoch 21/30, Loss: 0.3525, Train Accuracy: 85.55%, Val Accuracy: 83.58%\n",
      "Epoch 22/30, Loss: 0.3448, Train Accuracy: 85.87%, Val Accuracy: 82.84%\n",
      "Epoch 23/30, Loss: 0.3464, Train Accuracy: 85.55%, Val Accuracy: 84.33%\n",
      "Epoch 24/30, Loss: 0.3571, Train Accuracy: 85.55%, Val Accuracy: 84.33%\n",
      "Epoch 25/30, Loss: 0.3459, Train Accuracy: 85.87%, Val Accuracy: 82.84%\n",
      "Epoch 26/30, Loss: 0.3504, Train Accuracy: 86.04%, Val Accuracy: 82.84%\n",
      "Epoch 27/30, Loss: 0.3433, Train Accuracy: 85.39%, Val Accuracy: 84.33%\n",
      "Epoch 28/30, Loss: 0.3425, Train Accuracy: 85.55%, Val Accuracy: 84.33%\n",
      "Epoch 29/30, Loss: 0.3527, Train Accuracy: 86.36%, Val Accuracy: 82.09%\n",
      "Epoch 30/30, Loss: 0.3450, Train Accuracy: 85.71%, Val Accuracy: 83.58%\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update the weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate training loss and accuracy\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        val_accuracy = evaluate_model(model, val_loader)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    return train_losses, val_accuracies\n",
    "\n",
    "# Evaluation on validation set\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Train the model\n",
    "train_losses, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 75.37%\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
